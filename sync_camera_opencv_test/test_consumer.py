#!/usr/bin/env python3

import cv2
import numpy as np
import socket
import threading
import time
import sys
import queue

class AdaptiveCameraClient:
    def __init__(self, host='127.0.0.1', start_port=5010, width=640, height=480):
        self.host = host
        self.start_port = start_port
        self.width = width
        self.height = height
        self.frame_size = width * height * 3 // 2  # I420
        
        self.running = False
        self.start_time = None
        self.camera_mode = None  # 'dual', 'triple', 'quad'
        
        # åŠ¨æ€æ‘„åƒå¤´é˜Ÿåˆ—å’Œè®¡æ•°å™¨
        self.camera_queues = []
        self.frame_counters = []
        self.camera_names = ["Left", "Right", "Third", "Fourth"]  # æ–°å¢ç¬¬å››ä¸ªæ‘„åƒå¤´
        self.camera_ports = []
        
        # æ˜¾ç¤ºæ¨¡å¼
        self.display_mode = 'combined'  # 'separate' æˆ– 'combined'
        
        # æ€§èƒ½é˜ˆå€¼ï¼ˆé’ˆå¯¹ä¸åŒæ¨¡å¼ï¼‰
        self.fps_thresholds = {
            'dual': 28,    # åŒæ‘„åƒå¤´30fps
            'triple': 18,  # ä¸‰æ‘„åƒå¤´20fps
            'quad': 16     # å››æ‘„åƒå¤´18fps
        }
    
    def detect_available_streams(self):
        """æ£€æµ‹å¯ç”¨çš„æ‘„åƒå¤´æµ"""
        print(f"[DETECTION] Detecting available camera streams starting from port {self.start_port}...")
        
        available_ports = []
        
        # æ£€æµ‹æœ€å¤š4ä¸ªç«¯å£
        for i in range(4):
            port = self.start_port + i
            try:
                test_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                test_sock.settimeout(3)
                result = test_sock.connect_ex((self.host, port))
                test_sock.close()
                
                if result == 0:
                    available_ports.append(port)
                    print(f"[DETECTION] âœ“ Found camera stream on port {port}")
                else:
                    print(f"[DETECTION] âœ— Port {port} not available")
                    break  # å‡è®¾ç«¯å£æ˜¯è¿ç»­çš„
            except:
                print(f"[DETECTION] âœ— Cannot test port {port}")
                break
        
        # ç¡®å®šæ¨¡å¼
        if len(available_ports) >= 4:
            self.camera_mode = 'quad'
            self.camera_ports = available_ports[:4]
            print(f"[DETECTION] Mode: Quad Camera ({len(self.camera_ports)} streams)")
        elif len(available_ports) >= 3:
            self.camera_mode = 'triple'
            self.camera_ports = available_ports[:3]
            print(f"[DETECTION] Mode: Triple Camera ({len(self.camera_ports)} streams)")
        elif len(available_ports) >= 2:
            self.camera_mode = 'dual'
            self.camera_ports = available_ports[:2]
            print(f"[DETECTION] Mode: Dual Camera ({len(self.camera_ports)} streams)")
        else:
            self.camera_mode = 'none'
            print(f"[DETECTION] Error: Need at least 2 camera streams")
            return False
        
        # åˆå§‹åŒ–é˜Ÿåˆ—å’Œè®¡æ•°å™¨
        for i in range(len(self.camera_ports)):
            self.camera_queues.append(queue.Queue(maxsize=3))  # å¢åŠ é˜Ÿåˆ—å¤§å°
            self.frame_counters.append([0])
        
        return True
    
    def i420_to_bgr(self, data):
        """I420è½¬BGR - å®Œæ•´å½©è‰²è½¬æ¢"""
        try:
            y_size = self.width * self.height
            uv_size = y_size // 4
            
            # æå–YUVä¸‰ä¸ªå¹³é¢
            y_plane = np.frombuffer(data[:y_size], dtype=np.uint8).reshape(self.height, self.width)
            u_plane = np.frombuffer(data[y_size:y_size + uv_size], dtype=np.uint8).reshape(self.height//2, self.width//2)
            v_plane = np.frombuffer(data[y_size + uv_size:], dtype=np.uint8).reshape(self.height//2, self.width//2)
            
            # ä¸Šé‡‡æ ·Uå’ŒVå¹³é¢åˆ°åŸå§‹å°ºå¯¸
            u_upsampled = cv2.resize(u_plane, (self.width, self.height), interpolation=cv2.INTER_LINEAR)
            v_upsampled = cv2.resize(v_plane, (self.width, self.height), interpolation=cv2.INTER_LINEAR)
            
            # åˆå¹¶YUVå¹³é¢
            yuv_img = np.dstack([y_plane, u_upsampled, v_upsampled])
            
            # YUVè½¬BGR
            bgr_img = cv2.cvtColor(yuv_img, cv2.COLOR_YUV2BGR)
            
            return bgr_img
            
        except Exception as e:
            print(f"I420è½¬æ¢é”™è¯¯: {e}")
            return None
    
    def add_frame_info(self, frame, camera_name, port, frame_count, camera_index):
        """åœ¨å¸§ä¸Šæ·»åŠ ä¿¡æ¯å åŠ """
        if frame is None:
            return None
            
        # è®¡ç®—FPS
        elapsed = time.time() - self.start_time if self.start_time else 0
        fps = frame_count / elapsed if elapsed > 0 else 0
        
        # æ·»åŠ åŠé€æ˜èƒŒæ™¯
        overlay = frame.copy()
        cv2.rectangle(overlay, (5, 5), (300, 180), (0, 0, 0), -1)
        frame = cv2.addWeighted(frame, 0.7, overlay, 0.3, 0)
        
        # é€‰æ‹©é¢œè‰²ï¼ˆåŒºåˆ†æ‘„åƒå¤´ï¼‰
        colors = [(0, 255, 0), (0, 255, 255), (255, 0, 255), (255, 128, 0)]  # ç»¿ã€é»„ã€å“çº¢ã€æ©™
        color = colors[camera_index % len(colors)]
        
        # ç»˜åˆ¶ä¿¡æ¯æ–‡æœ¬
        cv2.putText(frame, f'{camera_name} Camera', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
        cv2.putText(frame, f'FPS: {fps:.1f}', (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        cv2.putText(frame, f'Frames: {frame_count}', (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        cv2.putText(frame, f'Port: {port}', (10, 120), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        cv2.putText(frame, f'Mode: {self.camera_mode.upper()}', (10, 145), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        # ä¸ºå››æ‘„åƒå¤´æ¨¡å¼æ·»åŠ ç‰¹æ®Šæ ‡è¯†
        if self.camera_mode == 'quad':
            if camera_index == 2:  # ç¬¬ä¸‰æ‘„åƒå¤´ï¼ˆæ’å€¼ï¼‰
                cv2.putText(frame, 'INTERPOLATED', (10, 170), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
            cv2.putText(frame, f'Cam {camera_index}', (250, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        return frame
    
    def socket_stream_worker(self, port, camera_name, camera_index):
        """Socketæµå·¥ä½œçº¿ç¨‹"""
        try:
            print(f"[{camera_name}] Connecting to port {port}...")
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(15)  # å¢åŠ è¶…æ—¶æ—¶é—´
            sock.connect((self.host, port))
            print(f"[{camera_name}] âœ“ Connected to port {port}")
            
            # ä¸ºå››æ‘„åƒå¤´æ¨¡å¼æ·»åŠ ç¼“å†²åŒºä¼˜åŒ–
            if self.camera_mode == 'quad':
                sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 1024*1024)  # 1MBæ¥æ”¶ç¼“å†²åŒº
            
            while self.running:
                # è¯»å–å®Œæ•´çš„I420å¸§
                frame_data = b''
                while len(frame_data) < self.frame_size:
                    remaining = self.frame_size - len(frame_data)
                    chunk_size = min(remaining, 16384)  # å¢åŠ å—å¤§å°
                    chunk = sock.recv(chunk_size)
                    if not chunk:
                        print(f"[{camera_name}] Connection closed")
                        return
                    frame_data += chunk
                
                # è½¬æ¢ä¸ºå½©è‰²å›¾åƒ
                bgr_frame = self.i420_to_bgr(frame_data)
                if bgr_frame is not None:
                    self.frame_counters[camera_index][0] += 1
                    
                    # æ·»åŠ ä¿¡æ¯å åŠ 
                    bgr_frame = self.add_frame_info(
                        bgr_frame, camera_name, port, 
                        self.frame_counters[camera_index][0], camera_index
                    )
                    
                    # å°†å¤„ç†å¥½çš„å›¾åƒæ”¾å…¥é˜Ÿåˆ—
                    try:
                        self.camera_queues[camera_index].put_nowait(bgr_frame)
                    except queue.Full:
                        # å¦‚æœé˜Ÿåˆ—å·²æ»¡ï¼Œæ¸…ç©ºé˜Ÿåˆ—å¹¶æ”¾å…¥æ–°å¸§
                        try:
                            self.camera_queues[camera_index].get_nowait()
                            self.camera_queues[camera_index].put_nowait(bgr_frame)
                        except queue.Empty:
                            pass
                        
        except Exception as e:
            print(f"[{camera_name}] Error: {e}")
        finally:
            try:
                sock.close()
            except:
                pass
    
    def create_combined_display(self, frames):
        """åˆ›å»ºåˆå¹¶æ˜¾ç¤º"""
        if self.camera_mode == 'dual':
            # åŒæ‘„åƒå¤´ï¼šå·¦å³å¸ƒå±€
            canvas_width = self.width * 2
            canvas_height = self.height
            canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)
            
            # å·¦æ‘„åƒå¤´
            if frames[0] is not None:
                canvas[0:self.height, 0:self.width] = frames[0]
            else:
                cv2.putText(canvas, 'Left Camera\nNo Signal', (50, self.height//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # å³æ‘„åƒå¤´
            if frames[1] is not None:
                canvas[0:self.height, self.width:canvas_width] = frames[1]
            else:
                cv2.putText(canvas, 'Right Camera\nNo Signal', (self.width + 50, self.height//2), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # æ·»åŠ åˆ†å‰²çº¿
            cv2.line(canvas, (self.width, 0), (self.width, self.height), (255, 255, 255), 2)
            
        elif self.camera_mode == 'triple':
            # ä¸‰æ‘„åƒå¤´ï¼š2x2å¸ƒå±€ï¼ˆå·¦ä¸Šã€å³ä¸Šã€åº•éƒ¨ä¸­å¤®ï¼‰
            canvas_width = self.width * 2
            canvas_height = self.height * 2
            canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)
            
            # å·¦ä¸Šï¼šå·¦æ‘„åƒå¤´
            if frames[0] is not None:
                canvas[0:self.height, 0:self.width] = frames[0]
            
            # å³ä¸Šï¼šå³æ‘„åƒå¤´
            if frames[1] is not None:
                canvas[0:self.height, self.width:canvas_width] = frames[1]
            
            # åº•éƒ¨ä¸­å¤®ï¼šç¬¬ä¸‰æ‘„åƒå¤´
            if frames[2] is not None:
                start_x = self.width // 2
                start_y = self.height
                canvas[start_y:start_y + self.height, start_x:start_x + self.width] = frames[2]
            
            # æ·»åŠ åˆ†å‰²çº¿
            cv2.line(canvas, (self.width, 0), (self.width, self.height), (255, 255, 255), 2)
            cv2.line(canvas, (0, self.height), (canvas_width, self.height), (255, 255, 255), 2)
            
        else:  # quad
            # å››æ‘„åƒå¤´ï¼š2x2æ ‡å‡†ç½‘æ ¼å¸ƒå±€
            canvas_width = self.width * 2
            canvas_height = self.height * 2
            canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)
            
            # å·¦ä¸Šï¼šå·¦æ‘„åƒå¤´ (Cam 0)
            if frames[0] is not None:
                canvas[0:self.height, 0:self.width] = frames[0]
            else:
                self._draw_no_signal(canvas, "Left Camera\n(Cam 0)", 0, 0)
            
            # å³ä¸Šï¼šå³æ‘„åƒå¤´ (Cam 1)
            if frames[1] is not None:
                canvas[0:self.height, self.width:canvas_width] = frames[1]
            else:
                self._draw_no_signal(canvas, "Right Camera\n(Cam 1)", self.width, 0)
            
            # å·¦ä¸‹ï¼šç¬¬ä¸‰æ‘„åƒå¤´ (Cam 2, æ’å€¼)
            if frames[2] is not None:
                canvas[self.height:canvas_height, 0:self.width] = frames[2]
            else:
                self._draw_no_signal(canvas, "Third Camera\n(Cam 2, Interpolated)", 0, self.height)
            
            # å³ä¸‹ï¼šç¬¬å››æ‘„åƒå¤´ (Cam 3)
            if frames[3] is not None:
                canvas[self.height:canvas_height, self.width:canvas_width] = frames[3]
            else:
                self._draw_no_signal(canvas, "Fourth Camera\n(Cam 3)", self.width, self.height)
            
            # æ·»åŠ åˆ†å‰²çº¿
            cv2.line(canvas, (self.width, 0), (self.width, canvas_height), (255, 255, 255), 2)
            cv2.line(canvas, (0, self.height), (canvas_width, self.height), (255, 255, 255), 2)
            
            # ä¸ºå››æ‘„åƒå¤´æ¨¡å¼æ·»åŠ ç‰¹æ®Šæ ‡è¯†
            cv2.putText(canvas, 'QUAD SYNC', (canvas_width - 150, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # æ·»åŠ æ•´ä½“ä¿¡æ¯
        total_frames = sum(counter[0] for counter in self.frame_counters)
        elapsed = time.time() - self.start_time if self.start_time else 0
        overall_fps = total_frames / (elapsed * len(self.camera_ports)) if elapsed > 0 else 0
        
        info_y = canvas.shape[0] - 30
        mode_display = f'{self.camera_mode.capitalize()} Camera Sync'
        if self.camera_mode == 'quad':
            mode_display += ' (with Interpolation)'
        
        cv2.putText(canvas, f'{mode_display} - Overall FPS: {overall_fps:.1f}', 
                   (10, info_y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        return canvas
    
    def _draw_no_signal(self, canvas, text, start_x, start_y):
        """ç»˜åˆ¶æ— ä¿¡å·æç¤º"""
        text_lines = text.split('\n')
        y_offset = self.height // 2 - len(text_lines) * 15
        for i, line in enumerate(text_lines):
            cv2.putText(canvas, line, (start_x + 50, start_y + y_offset + i * 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
    
    def display_frames_separate(self):
        """åˆ†çª—å£æ˜¾ç¤ºæ‘„åƒå¤´"""
        # åˆ›å»ºçª—å£
        window_names = []
        for i, name in enumerate(self.camera_names[:len(self.camera_ports)]):
            window_name = f"{name} Camera"
            window_names.append(window_name)
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, self.width, self.height)
            
            # è®¾ç½®çª—å£ä½ç½®
            if self.camera_mode == 'dual':
                cv2.moveWindow(window_name, 50 + i * (self.width + 20), 50)
            elif self.camera_mode == 'triple':
                positions = [(50, 50), (50 + self.width + 20, 50), (50 + self.width//2, 50 + self.height + 50)]
                cv2.moveWindow(window_name, positions[i][0], positions[i][1])
            else:  # quad
                # 2x2å¸ƒå±€
                row = i // 2
                col = i % 2
                x = 50 + col * (self.width + 20)
                y = 50 + row * (self.height + 50)
                cv2.moveWindow(window_name, x, y)
        
        while self.running:
            # æ˜¾ç¤ºæ¯ä¸ªæ‘„åƒå¤´
            for i, window_name in enumerate(window_names):
                if not self.camera_queues[i].empty():
                    frame = self.camera_queues[i].get()
                    cv2.imshow(window_name, frame)
            
            # æ£€æŸ¥é€€å‡ºå’Œæ¨¡å¼åˆ‡æ¢
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                self.running = False
                break
            elif key == ord('c'):
                self.display_mode = 'combined'
                cv2.destroyAllWindows()
                return
            
            time.sleep(0.001)
    
    def display_frames_combined(self):
        """åˆå¹¶æ˜¾ç¤ºæ‘„åƒå¤´"""
        window_name = f"{self.camera_mode.capitalize()} Camera View"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        
        if self.camera_mode == 'dual':
            cv2.resizeWindow(window_name, self.width * 2, self.height)
        else:  # triple æˆ– quad
            cv2.resizeWindow(window_name, self.width * 2, self.height * 2)
        
        frames = [None] * len(self.camera_ports)
        
        while self.running:
            # è·å–æœ€æ–°å¸§
            for i in range(len(self.camera_ports)):
                if not self.camera_queues[i].empty():
                    frames[i] = self.camera_queues[i].get()
            
            # åˆ›å»ºåˆå¹¶æ˜¾ç¤º
            combined_frame = self.create_combined_display(frames)
            cv2.imshow(window_name, combined_frame)
            
            # æ£€æŸ¥é€€å‡ºå’Œæ¨¡å¼åˆ‡æ¢
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                self.running = False
                break
            elif key == ord('s'):
                self.display_mode = 'separate'
                cv2.destroyAllWindows()
                return
            
            time.sleep(0.001)
    
    def display_frames(self):
        """ä¸»æ˜¾ç¤ºå¾ªç¯ - æ”¯æŒæ¨¡å¼åˆ‡æ¢"""
        while self.running:
            if self.display_mode == 'separate':
                self.display_frames_separate()
            else:
                self.display_frames_combined()
    
    def run_adaptive_stream(self):
        """è¿è¡Œè‡ªé€‚åº”æ‘„åƒå¤´æµ"""
        print("="*80)
        print("Adaptive Multi-Camera Sync Client")
        print("Automatically detects dual/triple/quad camera configuration")
        print("="*80)
        
        # æ£€æµ‹å¯ç”¨æµ
        if not self.detect_available_streams():
            return False
        
        print(f"Mode: {self.camera_mode.upper()} camera sync")
        print(f"Ports: {', '.join(map(str, self.camera_ports))}")
        
        if self.camera_mode == 'quad':
            print("Special Features:")
            print("  - Camera 2 uses frame interpolation")
            print("  - Expected FPS: ~18")
        
        print("Controls:")
        print("  - Combined view: Press 'c'")
        print("  - Separate view: Press 's'") 
        print("  - Exit: Press 'q'")
        print("="*80)
        
        # å¯åŠ¨æµ
        self.running = True
        self.start_time = time.time()
        
        # åˆ›å»ºå·¥ä½œçº¿ç¨‹
        threads = []
        for i, port in enumerate(self.camera_ports):
            camera_name = self.camera_names[i]
            thread = threading.Thread(
                target=self.socket_stream_worker,
                args=(port, camera_name, i)
            )
            thread.daemon = True
            thread.start()
            threads.append(thread)
        
        # åœ¨ä¸»çº¿ç¨‹è¿è¡Œæ˜¾ç¤ºå¾ªç¯
        try:
            self.display_frames()
        except KeyboardInterrupt:
            print("\nUser interrupted")
            self.running = False
        
        # ç­‰å¾…å·¥ä½œçº¿ç¨‹ç»“æŸ
        for thread in threads:
            thread.join(timeout=2.0)
            
        cv2.destroyAllWindows()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        if self.start_time:
            elapsed = time.time() - self.start_time
            print(f"\nğŸ“Š {self.camera_mode.capitalize()} Camera Sync Statistics:")
            print(f"   Runtime: {elapsed:.1f} seconds")
            
            total_frames = 0
            fps_values = []
            for i, counter in enumerate(self.frame_counters):
                camera_name = self.camera_names[i]
                fps = counter[0] / elapsed if elapsed > 0 else 0
                fps_values.append(fps)
                
                # ä¸ºæ’å€¼æ‘„åƒå¤´æ·»åŠ æ ‡è¯†
                interpolated_mark = " (interpolated)" if (self.camera_mode in ['triple', 'quad'] and i == 2) else ""
                print(f"   {camera_name} Camera{interpolated_mark}: {counter[0]} frames ({fps:.1f} fps)")
                total_frames += counter[0]
            
            # åŒæ­¥è´¨é‡åˆ†æ
            avg_fps = total_frames / (elapsed * len(self.camera_ports)) if elapsed > 0 else 0
            print(f"   Average Sync FPS: {avg_fps:.1f}")
            
            # å¸§ç‡ä¸€è‡´æ€§åˆ†æ
            if len(fps_values) > 1:
                fps_std = np.std(fps_values)
                print(f"   Frame Rate Consistency: {fps_std:.2f} (lower is better)")
                
                # æ€§èƒ½è¯„ä¼°
                threshold = self.fps_thresholds.get(self.camera_mode, 15)
                if avg_fps > threshold:
                    print(f"   âœ“ Excellent {self.camera_mode} camera sync performance!")
                elif avg_fps > threshold * 0.8:
                    print(f"   âœ“ Good {self.camera_mode} camera sync performance!")
                else:
                    print(f"   âš  {self.camera_mode.capitalize()} sync performance could be improved")
                    print(f"     Expected: >{threshold} fps, Actual: {avg_fps:.1f} fps")
                
                # å››æ‘„åƒå¤´ç‰¹æ®Šåˆ†æ
                if self.camera_mode == 'quad':
                    print("   Quad Camera Analysis:")
                    
                    # åˆ†æä¸»æ‘„åƒå¤´ vs æ’å€¼æ‘„åƒå¤´æ€§èƒ½
                    main_cameras_fps = [fps_values[0], fps_values[1], fps_values[3]]  # 0,1,3æ˜¯ä¸»æ‘„åƒå¤´
                    interpolated_fps = fps_values[2]  # 2æ˜¯æ’å€¼æ‘„åƒå¤´
                    main_avg = np.mean(main_cameras_fps)
                    
                    print(f"     Main Cameras (0,1,3) Avg FPS: {main_avg:.1f}")
                    print(f"     Interpolated Camera (2) FPS: {interpolated_fps:.1f}")
                    
                    # æ’å€¼æ•ˆæœè¯„ä¼°
                    interpolation_ratio = interpolated_fps / main_avg if main_avg > 0 else 0
                    if interpolation_ratio > 1.5:
                        print("     âœ“ Excellent interpolation performance!")
                    elif interpolation_ratio > 1.0:
                        print("     âœ“ Good interpolation performance!")
                    else:
                        print("     âš  Interpolation may need optimization")
        
        return True

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        start_port = int(sys.argv[1])
    else:
        start_port = 5010
    
    print(f"Starting adaptive multi-camera client from port {start_port}")
    
    client = AdaptiveCameraClient(start_port=start_port)
    success = client.run_adaptive_stream()
    
    if success:
        print("âœ“ Adaptive multi-camera client exited normally")
    else:
        print("âœ— Adaptive multi-camera client exited with error")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())